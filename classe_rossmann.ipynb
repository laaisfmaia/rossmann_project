{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6ee4cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import inflection\n",
    "import math\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "import datetime\n",
    "from tabulate import tabulate\n",
    "from IPython.display import Image\n",
    "from scipy import stats as ss\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, LabelEncoder\n",
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import xgboost as xgb\n",
    "import random \n",
    "import pickle\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35499aae",
   "metadata": {},
   "source": [
    "### 0.2 Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a76ccda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales_raw = pd.read_csv(r'C:\\Users\\laism\\Downloads\\rossmann-store-sales\\train.csv', low_memory=False)\n",
    "\n",
    "df_store_raw = pd.read_csv(r'C:\\Users\\laism\\Downloads\\rossmann-store-sales\\store.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82a7cdf",
   "metadata": {},
   "source": [
    "## 10.1 Rossmann Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfda71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rossmann(object):\n",
    "    def __init__(self):\n",
    "        #carregando os parametros\n",
    "        self.competition_distance_scaler = pickle.load(open('parameter/competition_distance_scaler.pkl', 'rb'))\n",
    "        self.promo_time_week_scaler.pkl = pickle.load(open('parameter/promo_time_week_scaler.pkl.pkl', 'rb'))\n",
    "        self.competition_time_month_scaler = pickle.load(open('parameter/competition_time_month_scaler.pkl', 'rb'))\n",
    "        self.year_scaler = pickle.load(open('parameter/year_scaler.pkl', 'rb'))\n",
    "        self.store_type_scaler = pickle.load(open('parameter/store_type_scaler.pkl', 'rb'))\n",
    "\n",
    "        state = 1\n",
    "        \n",
    "    def data_cleaning(self, df1):\n",
    "\n",
    "        #renomeando as colunas\n",
    "        cols_old = ['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo',\n",
    "                   'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment',\n",
    "                   'CompetitionDistance', 'CompetitionOpenSinceMonth',\n",
    "                   'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek',\n",
    "                   'Promo2SinceYear', 'PromoInterval']\n",
    "\n",
    "        #função que deixa tudo minusculo e separado por _\n",
    "        snakecase = lambda x: inflection.underscore(x)\n",
    "        cols_new = list( map(snakecase, cols_old))\n",
    "\n",
    "        df1.columns = cols_new\n",
    "\n",
    "        #mudando o tipo da data\n",
    "        df1['date'] = pd.to_datetime(df1['date'])\n",
    "\n",
    "        #preenchendo os NA\n",
    "\n",
    "        #CompetitionDistance - distance in meters to the nearest competitor store\n",
    "        #vou assumir que se o valor é mt maior que a distância máxima que tem um competidor proximo então é a msm coisa que dizer que não tem um competidor proxim\n",
    "\n",
    "        max_value = df1['competition_distance'].max()\n",
    "        #isnan avalia se é NA\n",
    "        df1['competition_distance'] = df1['competition_distance'].apply( lambda x: 200000.0 if math.isnan(x) else x)\n",
    "\n",
    "        #CompetitionOpenSince[Month/Year] - gives the approximate year and month of the time the nearest competitor was opened\n",
    "        #vou assumir que é vazio pqe não tem um competidor mais proximo ou tem um competidor proximo mas não temos info de quando abriu\n",
    "        #vou substituir pelo mês da data da venda\n",
    "\n",
    "        df1['competition_open_since_month'] = df1.apply( lambda x: x['date'].month if math.isnan(x['competition_open_since_month']) else x['competition_open_since_month'], axis=1)\n",
    "\n",
    "        df1['competition_open_since_year'] = df1.apply( lambda x: x['date'].year if math.isnan(x['competition_open_since_year']) else x['competition_open_since_year'], axis=1)\n",
    "\n",
    "        #Promo2Since[Year/Week] - describes the year and calendar week when the store started participating in Promo2\n",
    "        #vou substituir pela data da venda\n",
    "\n",
    "        df1['promo2_since_week'] = df1.apply( lambda x: x['date'].week if math.isnan(x['promo2_since_week']) else x['promo2_since_week'], axis=1)\n",
    "\n",
    "        df1['promo2_since_year'] = df1.apply( lambda x: x['date'].year if math.isnan(x['promo2_since_year']) else x['promo2_since_year'], axis=1)\n",
    "\n",
    "        #PromoInterval - describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store\n",
    "        #dict para trocar o num pelo nome do mês\n",
    "        month_map = {1: 'Jan',\n",
    "                     2: 'Fev',\n",
    "                     3: 'Mar',\n",
    "                     4: 'Apr',\n",
    "                     5: 'May',\n",
    "                     6: 'Jun',\n",
    "                     7: 'Jul',\n",
    "                     8: 'Aug',\n",
    "                     9: 'Sept',\n",
    "                     10: 'Oct',\n",
    "                     11: 'Nov',\n",
    "                     12: 'Dec'}\n",
    "\n",
    "        #susbtitui o N/A por zero\n",
    "        df1['promo_interval'].fillna(0, inplace=True)\n",
    "\n",
    "        #extraindo o mês da data e aplicando o dicionario para fazer a tradução\n",
    "        df1['month_map'] = df1['date'].dt.month.map(month_map)\n",
    "\n",
    "        #avaliação se o month_map está dentro do intervalo para ver se a loja está na promoção (1) ou não (0)\n",
    "        df1['is_promo'] = df1[['promo_interval','month_map']].apply( lambda x: 0 if x['promo_interval'] == 0 else 1 if x['month_map'] in x['promo_interval'].split(',') else 0, axis=1)\n",
    "\n",
    "        #mudando os tipos de dados\n",
    "        #passando para inteiro\n",
    "        df1['competition_open_since_month'] = df1['competition_open_since_month'].astype(int)\n",
    "\n",
    "        df1['competition_open_since_year'] = df1['competition_open_since_year'].astype(int)\n",
    "\n",
    "        df1['promo2_since_week'] = df1['promo2_since_week'].astype(int)\n",
    "\n",
    "        df1['promo2_since_year'] = df1['promo2_since_year'].astype(int)\n",
    "        \n",
    "        return df1\n",
    "    \n",
    "    def feature_engineering(self, df2):\n",
    "    \n",
    "        #year\n",
    "        df2['year'] = df2['date'].dt.year\n",
    "\n",
    "        #month\n",
    "        df2['month'] = df2['date'].dt.month\n",
    "\n",
    "        #day\n",
    "        df2['day'] = df2['date'].dt.day\n",
    "\n",
    "        #week of year\n",
    "        df2['week_of_wear'] = df2['date'].dt.weekofyear\n",
    "\n",
    "        #year week\n",
    "        df2['year_week'] = df2['date'].dt.strftime('%Y-%W')\n",
    "\n",
    "        #cometition since\n",
    "        #juntando as duas informações de data (ano e mês) em uma coluna só\n",
    "        #datetime.datetime() é uma função que monta uma data apartir de valores\n",
    "        df2['competion_since'] = df2.apply( lambda x: datetime.datetime(year = x['competition_open_since_year'], month = x['competition_open_since_month'], day=1), axis=1)\n",
    "        df2['competion_time_month'] = ((df2['date'] - df2['competion_since'])/30 ).apply(lambda x: x.days).astype(int)\n",
    "\n",
    "        #promo since\n",
    "        df2['promo_since'] = df2['promo2_since_year'].astype(str) + '-' + df2['promo2_since_week'].astype(str)\n",
    "\n",
    "        #trocando caracter para o tipo data\n",
    "        df2['promo_since'] = df2['promo_since'].apply(lambda x: datetime.datetime.strptime( x + '-1', '%Y-%W-%w') - datetime.timedelta(days=7))\n",
    "\n",
    "        df2['promo_time_week'] = ((df2['date'] - df2['promo_since'])/7).apply(lambda x: x.days).astype(int)\n",
    "\n",
    "        #assortment\n",
    "        #Assortment - describes an assortment level: a = basic, b = extra, c = extended\n",
    "        df2['assortment'] = df2['assortment'].apply(lambda x: 'basic' if x == 'a' else 'extra' if x == 'b' else 'extended')\n",
    "\n",
    "        #state holiday\n",
    "        #StateHoliday - indicates a state holiday. Normally all stores, with few exceptions, are closed on state holidays. Note that all schools are closed on public holidays and weekends. \n",
    "        #a = public holiday, b = Easter holiday, c = Christmas, 0 = None\n",
    "\n",
    "        df2['state_holiday'] = df2['state_holiday'].apply( lambda x: 'public_holiday' if x == 'a' else 'easter_holiday' if x == 'b' else 'christmas' if x == 'c' else 'regular_day')\n",
    "\n",
    "        ######filtragem de variáveis\n",
    "        #filtrando linhas\n",
    "        #só vou usar as vendas em que open é diferente de zero\n",
    "        #sellers tem que ser maior que zero\n",
    "        df2 = df2[(df2['open'] != 0) & (df2['sales'] > 0)]\n",
    "        \n",
    "        #seleção das colunas \n",
    "        #baseado no contexto, não vamos ter a coluna customers no momento da previsão pqe não tem como prever quantos customers vai ter\n",
    "        #promo interval foi derivada e month map é uma coluna auxiliar\n",
    "        #a coluna open como foi filtrada só tem valor 1\n",
    "        cols_drop = ['customers', 'open','promo_interval','month_map']\n",
    "        df2 = df2.drop(cols_drop, axis=1)\n",
    "        \n",
    "        return df2\n",
    "    \n",
    "    def data_preparation(self, df5):\n",
    "        ## 5.2 Rescaling\n",
    "        #Técnica Robust Scaler\n",
    "        #criando a msm variavel mas em uma nova escala\n",
    "\n",
    "        #competition_distance\n",
    "        df5['competition_distance'] = self.competition_distance_scaler.fit_transform(df5[['competition_distance']].values)\n",
    "\n",
    "        #competition time month\n",
    "        df5['competition_time_month'] = self.competition_time_month_scaler.fit_transform(df5[['competition_time_month']].values)\n",
    "\n",
    "        #Técnica Min-Max Scaler:\n",
    "        #promo time week\n",
    "        df5['promo_time_week'] = self.promo_time_week_scaler.fit_transform(df5[['promo_time_week']].values)\n",
    "\n",
    "        #year\n",
    "        df5['year'] = self.year_scaler.fit_transform(df5[['year']].values)\n",
    "\n",
    "        ## 5.3 Transformação\n",
    "        ### 5.3.1 Encoding\n",
    "        #variaveis categoricas: state_holiday , store_type e assortment\n",
    "\n",
    "        #state_holiday - One Hot Encoding\n",
    "        #cria uma coluna pra cada tipo colocando 1 ou 0\n",
    "        df5 = pd.get_dummies( df5, prefix=['state_holiday'], columns = ['state_holiday'])\n",
    "\n",
    "        #store_type - Label Encoding\n",
    "        #substitui a categoria por número\n",
    "        df5['store_type'] = self.store_type_scaler.fit_transform(df5['store_type'])\n",
    "\n",
    "        #assortment - Ordinal Encoding\n",
    "        #substitui a categoria por número de forma ordenada\n",
    "        assortment_dict = {'basic': 1,\n",
    "                           'extra': 2,\n",
    "                           'extended': 3}\n",
    "        df5['assortment'] = df5['assortment'].map(assortment_dict)\n",
    "\n",
    "        ### 5.3.3 Nature Transformation\n",
    "\n",
    "        #separando quais variáveis tem natureza ciclica \n",
    "        #month\n",
    "        df5['month_sin'] = df5['month'].apply( lambda x: np.sin( x * (2. * np.pi/12)))\n",
    "        df5['month_cos'] = df5['month'].apply( lambda x: np.cos( x * (2. * np.pi/12)))\n",
    "\n",
    "        #day\n",
    "        df5['day_sin'] = df5['day'].apply( lambda x: np.sin( x * (2. * np.pi/30)))\n",
    "        df5['day_cos'] = df5['day'].apply( lambda x: np.cos( x * (2. * np.pi/30)))\n",
    "\n",
    "        #week of year\n",
    "        df5['week_of_year_sin'] = df5['week_of_year'].apply( lambda x: np.sin( x * (2. * np.pi/52)))\n",
    "        df5['week_of_year_cos'] = df5['week_of_year'].apply( lambda x: np.cos( x * (2. * np.pi/52)))\n",
    "\n",
    "        #day_of_week\n",
    "        df5['day_of_week_sin'] = df5['day_of_week'].apply( lambda x: np.sin( x * (2. * np.pi/7)))\n",
    "        df5['day_of_week_cos'] = df5['day_of_week'].apply( lambda x: np.cos( x * (2. * np.pi/7)))\n",
    "\n",
    "        cols_selected = ['store', 'promo', 'store_type', 'assortment', 'competition_distance', 'competition_open_since_month', 'competition_open_since_year', 'promo2', 'promo2_since_week', 'promo2_since_year', 'competition_time_month', 'promo_time_week', 'month_cos', 'month_sin', 'day_sin', 'day_cos', 'week_of_year_sin', 'week_of_year_cos', 'day_of_week_sin', 'day_of_week_cos']\n",
    "        \n",
    "        return df5[cols_selected]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08646c39",
   "metadata": {},
   "source": [
    "## 10.2 API Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6df5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import pandas as pd\n",
    "from flask import Flask, request\n",
    "from Rossman import Rossmann\n",
    "\n",
    "#carregando o modelo\n",
    "model = pickle.load( open(r'model_rossmann.pkl', 'rb'))\n",
    "\n",
    "#inicializando a API\n",
    "app = Flask(__name__)\n",
    "\n",
    "#criando o end point\n",
    "#POST é o metodo que envia dados \n",
    "@app.route('/rossmann/predict', methods=['POST'])\n",
    "\n",
    "#quando o end point recebe uma chamada vida post, ele executa a primeira função abaixo dele\n",
    "\n",
    "def rossmann_predict():\n",
    "    test_json = request.get_json()\n",
    "    \n",
    "    if test_json: #se tem dado, converte json em dataframe\n",
    "        if isinstance(test_json, dict): #exemplo unico\n",
    "            test_raw = pd.DataFrame(test_json, index=[0])\n",
    "        else: #exemplo multiplos\n",
    "            test_raw = pd.DataFrame(test_json, columns=test_json[0].keys())\n",
    "        \n",
    "        #instanciando a classe rossmann\n",
    "        pipeline = Rossmann()\n",
    "        \n",
    "        #data cleaning\n",
    "        df1 = pipeline.data_cleaning(test_raw)\n",
    "        \n",
    "        #feature enginnering\n",
    "        df2 = pipeline.feature_engineering(df1)\n",
    "        \n",
    "        #data preparation\n",
    "        df3 = pipeline.data_preparation(df2)\n",
    "        \n",
    "        #prediction\n",
    "        df_response = pipeline.Get_prediction(model, test_raw, df3)\n",
    "        \n",
    "        return df_response\n",
    "\n",
    "        \n",
    "    else: #se não tem dado\n",
    "        return Response('{}', status=200, mimetype='application/json')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #'0.0.0.0' end point do local host\n",
    "    app.run('0.0.0.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e19db03",
   "metadata": {},
   "source": [
    "## 10.3 API Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88ec47e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cfa170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#carregando dados de teste\n",
    "df10 = pd.read_csv(r'C:\\Users\\laism\\Downloads\\rossmann-store-sales\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5a39fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge do dataset testes + store\n",
    "df_test = pd.merge(df10, df_store_raw, how='left', on = 'Store')\n",
    "\n",
    "#escolhendo a loja para predição\n",
    "#df_test = df_test[df_test['Store'].isin([24])]\n",
    "df_test = df_test[df_test['Store'] == 22]\n",
    "\n",
    "#remove dias fechados\n",
    "df_test = df_test[df_test['Open'] != 0]\n",
    "#removendo lojas vazias\n",
    "df_test = df_test[~df_test['Open'].isnull()]\n",
    "#apagando a coluna id\n",
    "df_test = df_test.drop('Id', axis=1)\n",
    "\n",
    "#convertendo df para Json\n",
    "import json\n",
    "data = json.dumps(df_test.to_dict(orient = 'records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1302d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Call\n",
    "#url é o end point, pra onde eu vou enviar o pedido\n",
    "url = 'http://192.168.0.214:5000/rossmann/predict'\n",
    "#url = 'http://0.0.0.0:5000/rossmann/predict'\n",
    "\n",
    "#header indica para ip que tipo de dado ela está recebendo\n",
    "header = { 'Content-type': 'application/json'}\n",
    "\n",
    "data = data\n",
    "#post é um metodo para enviar dados\n",
    "r = requests.post(url, data=data, headers=header)\n",
    "print('Status Code {}'.format(r.status_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58996955",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
